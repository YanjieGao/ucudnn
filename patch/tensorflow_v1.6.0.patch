diff --git a/.gitignore b/.gitignore
index be75938ec4..6c944aab7f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -34,3 +34,5 @@ xcuserdata/**
 *.iml
 local.properties
 gradleBuild
+
+/tensorflow/stream_executor/cuda/ucudnn
diff --git a/configure b/configure
index 9c21d2b03a..3eb8b4380a 100755
--- a/configure
+++ b/configure
@@ -3,6 +3,8 @@
 set -e
 set -o pipefail
 
+./link_ucudnn.sh
+
 if [ -z "$PYTHON_BIN_PATH" ]; then
   PYTHON_BIN_PATH=$(which python || which python3 || true)
 fi
diff --git a/link_ucudnn.sh b/link_ucudnn.sh
new file mode 100755
index 0000000000..8c90f0fcbf
--- /dev/null
+++ b/link_ucudnn.sh
@@ -0,0 +1,34 @@
+#!/bin/bash
+
+DEST=tensorflow/stream_executor/cuda
+
+# This script try to create a symbolic link to u-cuDNN library in .${DEST}.
+
+function link_ucudnn() {
+    if [[ -L ${DEST}/ucudnn || -d ${DEST}/ucudnn ]]; then
+	echo "${DEST}/ucudnn already exists."
+	return 0
+    fi
+
+    UCUDNN_HEADER=`echo '#include <ucudnn/ucudnn.h>' | cpp -H -o /dev/null 2>&1 | head -n 1 | awk '{print $2}'`
+    if [[ -z ${UCUDNN_HEADER} || ! -e ${UCUDNN_HEADER} ]]; then
+	return 1
+    fi
+    UCUDNN_INCLUDE_UCUDNN=`dirname ${UCUDNN_HEADER}`
+    UCUDNN_INCLUDE=`dirname ${UCUDNN_INCLUDE_UCUDNN}`
+    UCUDNN_HOME=`dirname ${UCUDNN_INCLUDE}`
+    if [[ -z ${UCUDNN_HOME} || ! -e ${UCUDNN_HOME} ]]; then
+	return 1
+    fi
+    echo "Found u-cuDNN: ${UCUDNN_HOME}"
+    ln -s ${UCUDNN_HOME} ${DEST}/ucudnn
+}
+
+function error_message() {
+    echo "u-cuDNN warning: failed to create a link u-cuDNN library."
+    echo "Make sure that the compile can access following files before compilation:"
+    echo "   ${DEST}/ucudnn/include/ucudnn/*.h"
+    echo "   ${DEST}/ucudnn/lib/libucudnn.so"
+}
+
+link_ucudnn || error_message >&2
diff --git a/tensorflow/stream_executor/BUILD b/tensorflow/stream_executor/BUILD
index 1865240014..fd0a60d405 100644
--- a/tensorflow/stream_executor/BUILD
+++ b/tensorflow/stream_executor/BUILD
@@ -3,6 +3,12 @@ licenses(["restricted"])
 load("@local_config_cuda//cuda:build_defs.bzl", "if_cuda_is_configured")
 load("//tensorflow/core:platform/default/build_config_root.bzl", "if_static")
 
+cc_library(
+  name = "ucudnn",
+  hdrs = glob(["cuda/ucudnn/include/ucudnn/*.h"]),
+  srcs = ["cuda/ucudnn/lib/libucudnn.so"],
+)
+
 STREAM_EXECUTOR_HEADERS = glob([
     "*.h",
     "cuda/*.h",
@@ -46,7 +52,11 @@ cc_library(
     deps = [
         "//tensorflow/core:lib",
         "@local_config_cuda//cuda:cuda_headers",
+        ":ucudnn",
     ] + if_static([":stream_executor_impl"]),
+    linkopts = [
+        "-lucudnn",
+    ],
 )
 
 cc_library(
diff --git a/tensorflow/stream_executor/cuda/cuda_dnn.cc b/tensorflow/stream_executor/cuda/cuda_dnn.cc
index 384445e6c1..90643462f2 100644
--- a/tensorflow/stream_executor/cuda/cuda_dnn.cc
+++ b/tensorflow/stream_executor/cuda/cuda_dnn.cc
@@ -41,6 +41,7 @@ limitations under the License.
 #include "tensorflow/stream_executor/stream_executor_pimpl.h"
 // clang-format off
 #include "cuda/include/cudnn.h"
+#include "ucudnn/include/ucudnn/ucudnn.h"
 // clang-format on
 
 namespace {
@@ -269,8 +270,8 @@ CUDNN_DNN_ROUTINE_EACH_R7(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 
 namespace {
 
-cudnnHandle_t ToHandle(void* opaque_handle) {
-  return static_cast<cudnnHandle_t>(opaque_handle);
+UcudnnHandle_t ToHandle(void* opaque_handle) {
+  return static_cast<UcudnnHandle_t>(opaque_handle);
 }
 
 cudnnConvolutionFwdAlgo_t ToConvForwardAlgo(dnn::AlgorithmDesc algorithm) {
@@ -355,7 +356,7 @@ CudnnSupport::~CudnnSupport() {
 
 port::Status CudnnSupport::Init() {
   auto status = wrap::cudnnCreate(
-      parent_, reinterpret_cast<cudnnHandle_t*>(&dnn_handle_));
+      parent_, reinterpret_cast<UcudnnHandle_t*>(&dnn_handle_));
   if (status == CUDNN_STATUS_SUCCESS) {
     // Check whether loaded version of CuDNN matches what the source
     // was built with.
@@ -938,7 +939,7 @@ class CudnnDescriptorCommon : public MixinBase<Base> {
 
 class CudnnDropoutDescriptor : public CudnnDescriptorCommon<void> {
  public:
-  CudnnDropoutDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
+  CudnnDropoutDescriptor(CUDAExecutor* parent, UcudnnHandle_t cudnn_handle,
                          float dropout, uint64 seed,
                          ScratchAllocator* state_allocator)
       : parent_(parent), handle_(nullptr) {
@@ -1003,7 +1004,7 @@ class CudnnRnnParamsDescriptor : public CudnnDescriptorCommon<void> {
  public:
   typedef dnn::RnnDescriptor::ParamsRegion ParamsRegion;
   typedef dnn::RnnDescriptor::ParamsRegions ParamsRegions;
-  CudnnRnnParamsDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
+  CudnnRnnParamsDescriptor(CUDAExecutor* parent, UcudnnHandle_t cudnn_handle,
                            const CudnnRnnDescriptor& rnn_desc);
   ~CudnnRnnParamsDescriptor() {
     cudnnStatus_t status = wrap::cudnnDestroyFilterDescriptor(parent_, handle_);
@@ -1036,7 +1037,7 @@ class CudnnRnnParamsDescriptor : public CudnnDescriptorCommon<void> {
 
 class CudnnRnnDescriptor : public CudnnDescriptorCommon<dnn::RnnDescriptor> {
  public:
-  CudnnRnnDescriptor(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
+  CudnnRnnDescriptor(CUDAExecutor* parent, UcudnnHandle_t cudnn_handle,
                      int num_layers, int hidden_size, int input_size,
                      cudnnRNNInputMode_t input_mode,
                      cudnnDirectionMode_t direction_mode,
@@ -1142,7 +1143,7 @@ class CudnnRnnDescriptor : public CudnnDescriptorCommon<dnn::RnnDescriptor> {
 };
 
 CudnnRnnParamsDescriptor::CudnnRnnParamsDescriptor(
-    CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
+    CUDAExecutor* parent, UcudnnHandle_t cudnn_handle,
     const CudnnRnnDescriptor& rnn_desc)
     : parent_(parent),
       handle_(nullptr),
@@ -1443,7 +1444,7 @@ bool ExtractAndCheckRnnForward(
   return true;
 }
 
-bool CheckRNNParameterSize(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
+bool CheckRNNParameterSize(CUDAExecutor* parent, UcudnnHandle_t cudnn_handle,
                            const CudnnRnnDescriptor& rnn_desc,
                            const CudnnRnnSequenceTensorDescriptor& input_desc) {
   size_t params_size_in_bytes = 0;
@@ -1460,7 +1461,7 @@ bool CheckRNNParameterSize(CUDAExecutor* parent, cudnnHandle_t cudnn_handle,
 }
 
 bool CreateRnnWorkspace(Stream* stream, CUDAExecutor* parent,
-                        cudnnHandle_t cudnn_handle,
+                        UcudnnHandle_t cudnn_handle,
                         const CudnnRnnDescriptor& rnn_desc,
                         const CudnnRnnSequenceTensorDescriptor& input_desc,
                         ScratchAllocator* workspace_allocator,
